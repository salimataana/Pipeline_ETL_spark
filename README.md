ccğŸ§© Projet ETL Modulaire et Standard avec PySpark

Ce projet est une implÃ©mentation d'un pipeline ETL (Extraction, Transformation, Chargement) modulaire utilisant PySpark. Il permet de traiter des donnÃ©es en plusieurs Ã©tapes indÃ©pendantes et testÃ©es.

ğŸ¯ Objectif
- Extraire les donnÃ©es depuis des sources variÃ©es (CSV, bases de donnÃ©es, etc)
- Transformer les donnÃ©es avec PySpark (nettoyage, traitements de valeurs manquantes, enrichissement)
- Charger les donnÃ©es transformÃ©es dans des formats optimisÃ©s (CSV, JSON, etc.)

ğŸ“ Structure du projet

.
â”œâ”€â”€ cores/
â”‚   â”œâ”€â”€ step.py                 # Classe abstraite Step
â”‚   â”œâ”€â”€ extract_csv.py          # Extraction depuis CSV
â”‚   â”œâ”€â”€ extract_bd.py           # Extraction depuis base de donnÃ©es
â”‚   â”œâ”€â”€ transform_main_csv.py   # Transformation des donnÃ©es CSV
â”‚   â”œâ”€â”€ transform_main_bd.py    # Transformation des donnÃ©es BD
â”‚   â”œâ”€â”€ load_bd.py              # Chargement format base
â”‚   â”œâ”€â”€ load_csv.py             # Chargement format fichier
â”‚   â””â”€â”€ utils.py                # Utilitaires et FileType
â”œâ”€â”€ main.py                     # Point d'entrÃ©e principal
â”œâ”€â”€ pipeline.py                 # Orchestration du pipeline
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ test_extract_bd.py
â”‚   â”œâ”€â”€ test_extract_csv.py
â”‚   â”œâ”€â”€ test_transform_bd.py
â”‚   â”œâ”€â”€ test_transform_bd_csv.py
â”‚   â”œâ”€â”€ test_load_bd.py
â”‚   â”œâ”€â”€ test_load_bd_csv.py
â”‚   â””â”€â”€ test_pipeline.py
â””â”€â”€ README.md


ğŸ§ª Tests
Chaque Ã©tape du pipeline est testÃ©e avec unittest pour garantir la fiabilitÃ© des traitements Spark.

ğŸš€ Lancement
ExÃ©cution via `main.py` qui orchestre l'enchaÃ®nement des Ã©tapes ETL avec gestion des sessions Spark.

ğŸ“Œ Ã€ propos
DÃ©veloppÃ© par Ana Salimata Sanou pour maÃ®triser la construction de pipelines data scalables avec PySpark et les bonnes pratiques de gÃ©nie logiciel.